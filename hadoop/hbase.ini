# a quick guide to install and configure hbase
# ref
#--------------------------------------------------------------------------
# http://hbase.apache.org/book/quickstart.html
# http://hbase.apache.org/book/example_config.html
# http://hbase.apache.org/book/config.files.html
# http://hbase.apache.org/book/zookeeper.html
# http://openwires.blogspot.com/p/hbase-multiple-node-setup-guide.html
# http://www.thecloudavenue.com/2012/02/getting-started-with-hbase-part-1.html
#--------------------------------------------------------------------------
# HBase provides real-time/random read/write access on top of HDFS. HBase runs a Master on one of the nodes (similar to NameNode/JobTracker) and RegionServer (similar to DataNode/TaskTracker) on the slave nodes.
#Notice the following anology between HDFS and HBASE. 
# HDFS 		HBase                                    
# NameNode	HMaster
# DataNode	HRegionServer
# SecondaryNameNode 	 None

# download hbase
wget http://.../hbase-0.94.12.tar.gz
tar xvf hbase-0.94.12.tar.gz
mv hbase-0.94.12.tar.gz hbase

# *************************************************************************
# 1) run hbase in standalone mode (default)
# *************************************************************************
# In standalone mode, HBase does not use HDFS -- it uses the local filesystem instead -- and it runs all HBase daemons and a local ZooKeeper all up in the same JVM. Zookeeper binds to a well known port so clients may talk to HBase.
# Pseudo-distributed mode can run against the local filesystem or it can run against an instance of the Hadoop Distributed File System (HDFS). 
# Fully-distributed mode can ONLY run on HDFS.

# no need to start hadoop
cd ~
hadoop/bin/stop-all.sh

cd hbase
# set JAVA_HOME for hbase
vim conf/hbase-env.sh
export JAVA_HOME=/usr/lib/jvm/javahome
# config hbase-site
vim conf/hbase-site.xml
<property>
    <name>hbase.rootdir</name>
    <value>file:///home/hduser/tmp/hbase</value>
  </property>
  <property>
   <name>hbase.zookeeper.property.dataDir</name>
    <value>/home/hduser/tmp/zookeeper</value>
  </property>

bin/start-hbase.sh
bin/hbase shell
hbase(main):001:0> list
# For some reason the HBase shell would hang.
# ref
#--------------------------------------------------------------------------
# http://hbase.apache.org/book/quickstart.html
# http://blog.devving.com/why-does-hbase-care-about-etchosts/
# http://amahanty.wordpress.com/2012/10/07/getting-started-with-hbase/
#--------------------------------------------------------------------------
#Loopback IP
#HBase expects the loopback IP address to be 127.0.0.1. Ubuntu and some other distributions, for example, will default to 127.0.1.1 and this will cause problems for you [1].

#/etc/hosts should look something like this:
#            127.0.0.1 localhost
#            127.0.0.1 ubuntu.ubuntu-domain ubuntu
#Fixed in 0.96.0+
#As of hbase-0.96.0+, this should no longer be an issue; it should work w/o special modification of /etc/hosts
# solution:
# 127.0.1.1	ubuntu --->127.0.0.1    ubuntu
vim /etc/hosts
127.0.0.1	localhost
127.0.0.1	master
# restart networking
/etc/init.d/networking restart

#-----------------------------------------------------------------------
# final /etc/hostname /etc/hosts /etc/network/interfaces
# master node
#************************************************************************
#hduer@master:~$ cat /etc/hostname
master
#hduser@master:~$ cat /etc/hosts
127.0.0.1	localhost
127.0.0.1	master
192.168.1.200 master
192.168.1.201 slave
#hduser@master:~$ cat /etc/network/interfaces 
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
address 192.168.1.200
netmask 255.255.255.0
gateway 192.168.1.1
network 192.168.1.0
broadcast 192.168.255
dns-nameservers 192.168.1.1

# slave node
#************************************************************************
#hduser@slave:~/hbase$ cat /etc/hostname
slave
#hduser@slave:~/hbase$ cat /etc/hosts
127.0.0.1	localhost
127.0.0.1	slave
192.168.1.200 master
192.168.1.201 slave
#hduser@slave:~/hbase$ cat /etc/network/interfaces 
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet static
address 192.168.1.201
netmask 255.255.255.0
gateway 192.168.1.1
network 192.168.1.0
broadcast 192.168.255
dns-nameservers 192.168.1.1
#-----------------------------------------------------------------------

bin/start-hbase.sh 
jps
#hduser@master:~/hbase$ jps
1932 HMaster

bin/hbase shell
hbase(main):001:0> version
#0.94.12, r1524863, Fri Sep 20 04:44:41 UTC 2013
hbase(main):002:0> list
#TABLE
# check localhost is master/127.0.0.1
hbase(main):003:0> java.net.InetAddress.localHost.to_s 
#=> "master/127.0.0.1"
hbase(main):004:0> java.net.InetAddress.localHost.getCanonicalHostName
#=> "localhost"
hbase(main):005:0> exit

bin/hbase shell
# http://wiki.apache.org/hadoop/Hbase/Shell
# http://hbase.apache.org/book/shell.html
# http://hbase.apache.org/book/quickstart.html#shell_exercises
hbase(main):001:0> version
#0.94.12, r1524863, Fri Sep 20 04:44:41 UTC 2013
hbase(main):002:0> create 'test', 'cf'
#0 row(s) in 1.2200 seconds
hbase(main):003:0> list 'test'
hbase(main):003:0> describe 'test'
#...
#1 row(s) in 0.0550 seconds
hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'
#0 row(s) in 0.0560 seconds
hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'
#0 row(s) in 0.0370 seconds
hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'
#0 row(s) in 0.0450 seconds

hbase(main):007:0> scan 'test'
#ROW        COLUMN+CELL
#row1       column=cf:a, timestamp=1288380727188, value=value1
#row2       column=cf:b, timestamp=1288380738440, value=value2
#row3       column=cf:c, timestamp=1288380747365, value=value3
#3 row(s) in 0.0590 seconds

hbase(main):008:0> flush 'test'

hbase(main):008:0> get 'test', 'row1'
#COLUMN      CELL
#cf:a        timestamp=1288380727188, value=value1
#1 row(s) in 0.0400 seconds

hbase(main):009:0> disable 'test'

hbase(main):010:0> scan 'test'
#ERROR: org.apache.hadoop.hbase.DoNotRetryIOException: test is disabled.

hbase(main):011:0> drop 'test'
hbase(main):012:0> list
hbase(main):013:0> exit

bin/stop-hbase.sh
#hduser@master:~/hbase$ bin/stop-hbase.sh 
#stopping hbase...............
jps

# *************************************************************************
# 2) run hbase in distributed mode 
# *************************************************************************
# ************************************
# 2.1) pesudo-distributed mode
# ************************************
# A pseudo-distributed mode is simply a fully-distributed mode run on a single host. Use this configuration testing and prototyping on HBase. Do not use this configuration for production nor for evaluating HBase performance
# tell HBase to run in (pseudo-)distributed mode rather than in default standalone mode. To do this, set the hbase.cluster.distributed property to true (Its default is false)
vim conf/hbase-site.xml
<configuration>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>
</configuration>
# With this configuration, HBase will start up an HBase Master process, a ZooKeeper server, and a RegionServer process running against the local filesystem writing to wherever your operating system stores temporary files into a directory named hbase-YOUR_USER_NAME
hduser@master:~/hbase$ bin/start-hbase.sh 
#localhost: starting zookeeper, logging to /home/hduser/hbase/bin/../logs/hbase-hduser-zookeeper-master.out
#starting master, logging to /home/hduser/hbase/bin/../logs/hbase-hduser-master-master.out
#localhost: starting regionserver, logging to /home/hduser/hbase/bin/../logs/hbase-hduser-regionserver-master.out

#bin/local-master-backup.sh start|stop
#bin/local-regionservers.sh start|stop
hduser@master:~/hbase$ jps
6568 HRegionServer
6379 HMaster
6308 HQuorumPeer
# Writing to the operating system's temporary directory can also make for data loss when the machine is restarted as this directory is usually cleared on reboot. For a more permanent setup, see the next example where we make use of an instance of HDFS; HBase data will be written to the Hadoop distributed filesystem rather than to the local filesystem's tmp directory.
bin/stop-hbase.sh
# or 
cat /tmp/hbase-${USER}-1-master.pid |xargs kill -9
#stopping hbase........................
#localhost: stopping zookeeper.
jps
# ************************************
# 2.2) fully-distributed mode (recommended)
# ************************************
vim conf/hbase-site.xml
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://master:54310/hbase</value>
    <description>The directory shared by RegionServers.</description>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>master</value>
    <description>if not set, regionserver in slave node will try to connect to localhost for zookeeper server and will fail </description>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/home/hduser/tmp/zookeeper</value>
  </property>
</configuration>
# regionservers
# In addition, a fully-distributed mode requires that you modify conf/regionservers. The "regionservers" file lists all hosts that you would have running HRegionServers, one host per line (This file in HBase is like the Hadoop slaves file). All servers listed in this file will be started and stopped when HBase cluster start or stop is run
# on master node
vim conf/regionservers
master
slave
# on slave node
vim conf/regionservers
localhost
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# The only difference between Master and Slave node is:
# master node: conf/regionservers are user defined
# slave node: conf/regionservers are default 'localhost'
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

# ZooKeeper and HBase
# See section Chapter 17, ZooKeeper for ZooKeeper setup for HBase.
# ---------------------------------------------------------------------
# http://hbase.apache.org/book/zookeeper.html
# http://hbase.apache.org/book/config.files.html
# ---------------------------------------------------------------------
# hbase.zookeeper.quorum
# By default this is set to localhost for local and pseudo-distributed modes of operation. For a fully-distributed setup, this should be set to a full list of ZooKeeper ensemble servers. If HBASE_MANAGES_ZK is set in hbase-env.sh this is the list of servers which hbase will start/stop ZooKeeper on as part of cluster start/stop. 

vim hbase/conf/hbase-site.xml
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>master</value>
    <description>if not set, regionserver in slave node will try to connect to localhost for zookeeper server and will fail </description>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/home/hduser/tmp/zookeeper</value>
  </property>

# hadoop 
# server side configuration file: core-site.xml mapred-site.xml
# client side hdfs configuration: hdfs-site.xml

# HDFS Client Configuration
# hadoop/conf/hdfs-site.xml
# Of note, if you have made HDFS client configuration on your Hadoop cluster -- i.e. configuration you want HDFS clients to use as opposed to server-side configurations -- HBase will not see this configuration unless you do ONE of the following:

# 1)Add a pointer to your HADOOP_CONF_DIR to the HBASE_CLASSPATH environment variable in hbase-env.sh.

# 2) Add a copy of hdfs-site.xml (or hadoop-site.xml) or, better, symlinks, under ${HBASE_HOME}/conf, or

# 3) if only a small set of HDFS client configurations, add them to hbase-site.xml.

#An example of such an HDFS client configuration is dfs.replication. If for example, you want to run with a replication factor of 5, hbase will create files with the default of 3 unless you do the above to make the configuration available to HBase.
vim conf/hbase-env.sh
export HBASE_CLASSPATH=/home/hduser/hadoop/conf

# Running and Confirming Your Installation
# first start hdfs
hadoop/bin/start-dfs.sh
jps
hbase/bin/start-hbase.sh
#hduser@master:~/hbase$ jps
9151 HRegionServer
3454 SecondaryNameNode
8962 HMaster
3242 DataNode
8903 HQuorumPeer
3030 NameNode
#hduser@slave:~/hbase$ jps
2871 DataNode
4855 HRegionServer

# hbase port
# server port
# HMaster 60000
# HRegionServer 60020
# zookeeper/HQuorumPeer 2181

# web port
# Master 60010
# RegionServer 60030

hbase/bin/hbase shell
#...
hbase/bin/stop-hbase.sh
# Shutdown can take a moment to complete. It can take longer if your cluster is comprised of many machines. If you are running a distributed operation, be sure to wait until HBase has shut down completely before stopping the Hadoop daemons.
hadoop/bin/start-dfs.sh

# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# ERROR: regionserver in slave node fail to start
# http://hbase.apache.org/book/trouble.client.html
# http://www.cnblogs.com/wukenaihe/archive/2013/03/15/2961029.html
# how to check
hduser@slave:~/hbase$ cat logs/hbase-hduser-regionserver-slave.out
# 13/10/23 19:22:12 WARN zookeeper.ClientCnxn: Session 0x0 for server null, un    expected error, closing socket connection and attempting reconnect
# 36 java.net.ConnectException: Connection refused
# 37         at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
# 38         at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java    :599)
# 39         at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSo    cketNIO.java:350)
# 40         at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:10    68)
# --------------------------------------------------------------------
# problem:
# regionserver in master node start, but failed in slave node
# because regionserver in slave node try to connect localhost:2181 for zookeeper,but it should be master:2181
# solution:

# on master and all slave nodes
vim conf/hbase-site.xml
	<property>
                <name>hbase.zookeeper.quorum</name>
                <value>master</value>
        </property>

# now the regionserver in slave node started
hduser@slave:~/hbase$ cat logs/hbase-hduser-regionserver-slave.out
# 36 13/10/23 20:20:02 INFO zookeeper.ClientCnxn: Socket connection established t    o master/192.168.1.200:2181, initiating session
# 37 13/10/23 20:20:02 INFO zookeeper.ClientCnxn: Session establishment complete     on server master/192.168.1.200:2181, sessionid = 0x141e879cdc40001, negotiat    ed timeout = 180000
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

# 3) Set up a sepatate zookeeper
# ref
#-------------------------------------------------------------------------
# http://openwires.blogspot.com/p/hbase-multiple-node-setup-guide.html
# http://hbase.apache.org/book/zookeeper.html
#-------------------------------------------------------------------------
# by default, zookeeper will be started by hbase/bin/start-hbase.sh
# now we will set up a separate zookeeper server and get rid of hbase's zookeeper
wget http://www.interior-dsgn.com/apache/zookeeper/stable/zookeeper-3.4.5.tar.gz
tar xvf zookeeper-3.4.5.tar.gz
mv zookeeper-3.4.5.tar.gz zookeeper

cd zookeeper/conf
cp zoo_sample.cfg zoo.cfg
# modify zoo.cfg
vim zoo.cfg
dataDir=/home/hduser/tmp/zookeeper
clientPort=2181
# get rid of the one which HBase starts. 
vim hbase/conf/hbase-env.sh
# Tell HBase whether it should manage it's own instance of Zookeeper or not.
export HBASE_MANAGES_ZK=False

# modify hbase-site.xml
vim hbase/conf/hbase-site.xml
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://master:54310/hbase</value>
    <description>The directory shared by RegionServers.</description>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>

  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>master</value>
    <description>if not set, regionserver in slave node will try to connect to localhost for zookeeper server and will fail </description>
  </property>

# First make sure nothing is running by checking jps. Or stop everything using stop-all.sh. Now try the following commands on the Master machine, which should start everything on slave also. 
jps
hadoop/bin/start-dfs.sh
#hduser@master:~$ jps
3454 SecondaryNameNode
3242 DataNode
3030 NameNode
#hduser@slave:~/hbase$ jps
2871 DataNode

zoopkeeper/bin/zkServer.sh start
#hduser@master:~$ jps
11547 QuorumPeerMain
3454 SecondaryNameNode
3242 DataNode
3030 NameNode

hbase/bin/start-hbase.sh
#hduser@master:~$ jps
12560 HMaster
11547 QuorumPeerMain
3454 SecondaryNameNode
12774 HRegionServer
3242 DataNode
3030 NameNode
#hduser@slave:~/hbase$ jps
2871 DataNode
6336 HRegionServer

# stop
hbase/bin/stop-hbase.sh
zoopkeeper/bin/zkServer.sh stop
hadoop/bin/stop-dfs.sh
